{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from load_data import load_images\n",
    "from losses import content_loss, style_loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from transforms import prep, post\n",
    "from torch.autograd import Variable\n",
    "from macros import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Current Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_images(2, 2)\n",
    "imgs = [prep(img) for img in imgs]\n",
    "imgs = [Variable(img.unsqueeze(0).to(device)) for img in imgs]\n",
    "img_con, img_sty = imgs\n",
    "opt_img = Variable(img_con.data.clone(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing from content image... Using pre-trained model VGG19_bn\n"
     ]
    }
   ],
   "source": [
    "print('Optimizing from content image... Using pre-trained model VGG19_bn')\n",
    "model = models.vgg19_bn(pretrained=True).to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSaver(nn.Module):\n",
    "    feature = None\n",
    "    def __init__(self, layer):\n",
    "        self.hook = layer.register_forward_hook(self.hook_func)\n",
    "    def hook_func(self, module, input, output):\n",
    "        self.feature = output\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content features from layer 37 of the model\n",
      "<generator object <genexpr> at 0x13d4dda80>\n"
     ]
    }
   ],
   "source": [
    "content_feature_savers = [FeatureSaver(model.features[layer]) for layer in content_layers]\n",
    "model(Variable(img_con))\n",
    "content_features = [saver.feature.clone() for saver in content_feature_savers]\n",
    "print(f'Saved content features from layer {content_layers[0]} of the model')\n",
    "style_feature_savers  = [FeatureSaver(model.features[layer]) for layer in style_layers]\n",
    "model(Variable(img_sty))\n",
    "style_features = [saver.feature.clone() for saver in style_feature_savers]\n",
    "print(f'Saved style features from layer {layer} of the model' for layer in style_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.LBFGS([opt_img])\n",
    "\n",
    "def closure():\n",
    "    global i\n",
    "    model(opt_img)\n",
    "    gen_content_feats = [saver.feature.clone() for saver in content_feature_savers]\n",
    "    gen_style_feats = [saver.feature.clone() for saver in style_feature_savers]\n",
    "\n",
    "    contentloss = WEIGHT_CONTENT * content_loss(gen_content_feats, content_features)\n",
    "    styleloss = style_loss(gen_style_feats, style_features, WEIGHTS_STYLE)\n",
    "    loss = contentloss + styleloss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    if i % show_iter == 0:\n",
    "        print(f\"Epoch: {i}, Content loss: {contentloss}, Style loss: {styleloss}, Total loss: {loss}\")\n",
    "    i += 1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "Epoch: 0, Content loss: 0.0, Style loss: 301846.03125, Total loss: 301846.03125\n",
      "Epoch: 50, Content loss: 0.005699015222489834, Style loss: 6062.5048828125, Total loss: 6062.5107421875\n",
      "Epoch: 100, Content loss: 0.006193954031914473, Style loss: 1069.41064453125, Total loss: 1069.4168701171875\n",
      "Epoch: 150, Content loss: 0.006436120253056288, Style loss: 355.30615234375, Total loss: 355.3125915527344\n",
      "Epoch: 200, Content loss: 0.006631428375840187, Style loss: 171.02200317382812, Total loss: 171.0286407470703\n",
      "Epoch: 250, Content loss: 0.0067511689849197865, Style loss: 101.37615966796875, Total loss: 101.3829116821289\n",
      "Epoch: 300, Content loss: 0.00684228865429759, Style loss: 68.37683868408203, Total loss: 68.38368225097656\n",
      "Epoch: 350, Content loss: 0.006915047764778137, Style loss: 50.1961669921875, Total loss: 50.20308303833008\n",
      "Epoch: 400, Content loss: 0.006958798039704561, Style loss: 39.56109619140625, Total loss: 39.56805419921875\n",
      "Epoch: 450, Content loss: 0.006990279071033001, Style loss: 32.584129333496094, Total loss: 32.59111785888672\n",
      "Training completed in 1588.94 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "i = 0\n",
    "print('Start Training...')\n",
    "while i < max_iter:\n",
    "    optimizer.step(closure)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "out_img = post(opt_img.data[0].cpu().squeeze())\n",
    "out_img.save('Result/kanagawa_ghibli.png', format='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
